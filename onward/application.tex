\section{Testing as a Boolean Compressed Sensing Problem}
As previously discussed, the boolean compressed sensing problem, also known as the group testing problem, extends compressed sensing to the problem of recovering a sparse signal from measurements that are logical products rather than vector products. This setup has application to any domain that consists of locating the members of a particular subset $\cal{M}$ of a population $\Sigma^*$. Suppose there exists a test that can determine whether any subset $\cal{O}\subseteq\Sigma^*$ of the population contains at least one member $\omega\in\cal{M}$ of the subset we are trying to find. Clearly, the entire subset $\cal{M}$ can be located by conducting tests on each singleton subset $\{\omega\}$ for each member $\omega\in\Sigma$, but this would require a large number of tests when the size of the population is large.  When the tests themselves are expensive or the population is simply too large, this procedure is usually not practical or even possible.  

Group testing is a method for locating the subset $\cal{M}$ by conducting as few tests as possible. We now formalize this problem to the application of testing for payloads. Let $\Sigma=\{ x_1,\ldots,x_n \}$ denote an alphabet and we call each individual element of the alphabet $x_i\in\Sigma$ a \emph{token}. In the context of security testing, our population is the set of strings that can be derived from tokens in $\Sigma$, and we denote this population of strings by $\Sigma^*$. We assume a finite bound on the length of strings in $\Sigma^*$. We use the notation $x\in\omega$ if token $x$ is used to derive string $\omega$. Assume that the subset ${\cal M} \subsetneq \Sigma^{\star}$ of the strings over $\Sigma$ are specified as malicious. We shall refer to these malicious strings as \emph{payloads}. 

In this application, testing subsets of the population $\Sigma^*$ is conducted by a so-called sanitizer. A sanitizer is a function 
$S \colon \Sigma^{\star} \rightarrow \Sigma^{\star}$ that maps between strings and we say that $S$ is \emph{correct} if
$$
\forall \omega \in \Sigma^{\star}.\ S(\omega) \notin {\cal M}.
$$ 
Given sanitizer $S$, string $\omega$, and token $x \in \omega$, we say that $S$ \emph{blocks} $x$ in $\omega$ if $x \notin S(\omega)$. We say that $S$ blocks $\omega$ if at least one of the tokens $x \in \omega$ is blocked.
% or relocated to a different position. Thus, $\omega$ is blocked if $\omega$ is not a substring of $S(\omega)$.

We are now ready to define our problem: Given sanitizer $S$, we would like to determine with \emph{high confidence} whether $S$ is correct. In other words, we would like to determine whether a sanitizer can recognize malicious strings in $\cal{M}$, where recognition means that if a sanitizer inputs a malicious string, it outputs a different non-malicious string. A naive solution is to simply traverse all the strings $\omega \in {\cal M}$ and apply $S$ to each of them in turn. We make the (realistic) assumption that ${\cal M}$ is prohibitively large, and so a heuristic is needed.

Another assumption is that many payloads in $\cal{M}$ share particular patterns that cause any string with such patterns to be blocked. If we can learn some of these patterns, the number of payloads that must be tested in order to determine correctness of a sanitizer can be greatly reduced. Stated intuitively, our idea is to test different random/arbitrary strings over $\Sigma$ (which may or may not be members of ${\cal M}$). Group testing can be used to identify tokens that cause some of these random strings to be blocked, and these \emph{malicious} tokens can be used to identify malicious patterns found in payloads. In another direction, the confidence of identifying malicious tokens can be used to prioritize payloads for testing.
If the confidence is high for token $x$, then the sanitizer is likely to block a string containing $x$, and so payloads in ${\cal M}$ that contain $x$ will be prioritized low, since we want to prioritize payloads that we know nothing about. 

%Let $T=\{t_1,\ldots,t_N\}$ be a set of $N$ strings to be tested where the $i^{th}$ string $t_i$ is composed of an arbitrary number of $n$ possible tokens.  Let $S$ be a sanitizer and define the function
%\[S(t)=
%\begin{cases} 1 &\mbox{if string } $t$ \mbox{ is accepted} \\
%0 & \mbox{otherwise}. 
%\end{cases} 
%\]
%The problem of testing is to determine whether or not a sanitizer $S$ accepts all strings in $T$ (a sanitizer is said to accept a string if it inputs the string and returns the same strong with no modifications).  Our goal is to provide a prioritization for sanitizing the strings in $T$ by determining which tokens are most associated with the sanitizer rejecting strings.  The idea is to create random strings, sanitize them, and learn which tokens define the results. 

Formally, let $U=\{\omega_1,\ldots,\omega_M\}$ be the set of $M$ random strings built from the possible tokens.  Define a matrix $A$ with $M$ rows and $N$ columns by 
\[A_{ij}=
\begin{cases} 1 &\mbox{if token } j \mbox{ appears in random string } i \\
0 & \mbox{otherwise}
\end{cases} 
\]
and the observed vector $y$ as $y_i=1-S(\omega_i)$ so that $y_i$ equals one if the $i^{th}$ random string is blocked by the sanitizer.  In practice, we known that sanitizer $S$ blocks string $\omega$ if $S(\omega)\neq\omega$ (i.e., at least one of the tokens in $\omega_i$ is not present in the sanitizer's output string).  Define a variable $x\in\{0,1\}^n$ such that $x_i=1$ if inclusion of the $i^{th}$ token in a string is cause for being blocked by the sanitizer.  Then our goal can be formulated by learning $x$ such that $A\vee xyb$, where $(A\vee x)_i=\vee_{j=1}^n(A_{ij}\wedge x_j)$, $\vee$ is the boolean OR operator, and $\wedge$ is the boolean AND operator.  We pose to learn $x$ by solving problem (\ref{eq:l0recovery}) which, as explained in Section \ref{s:boolean_compressed_sensing}, seeks to learn a minimal number of tokens that explain the output of the sanitizer. As this problem is not tractable, we solve problem (\ref{eq:booleanl1minLPslack}) in practice. 

%Note that since $x$ is boolean, $\|x\|_0=\sum_i{x_i}$.  Then the remaining difficulties of solving this problem are the logical multiplication and the binary constraints.  Firstly, as described in \cite{MalioutovM2012}, the logical multiplication $A\vee x=b$ can be replaced by the linear constraints $A_\mathcal{I}x\geq b_\mathcal{I}$ and $A_\mathcal{J}x=\textbf{0}_{|\mathcal{J}|}$ where $\mathcal{I}=\{i : b_i=1\}$ and $\mathcal{J}=\{i : b_i=0\}$, giving us the problem
%\[\begin{array}{ll}
%\mbox{minimize} & \sum_i{x_i}\\
%\mbox{subject to} & A_\mathcal{I}x\geq b_\mathcal{I} \\
%& A_\mathcal{J}x=\textbf{0}_{|\mathcal{J}|} \\
%& x\in\{0,1\}^n.
%\end{array}\]
%While this problem is still NP-hard (due to the binary constraints), under some (rather strong) assumptions about the sparsity of $x$, the optimal solution can be recovered by solving the following relaxation:
%\[\begin{array}{ll}
%\mbox{minimize} & \sum_i{x_i}\\
%\mbox{subject to} & A_\mathcal{I}x\geq b_\mathcal{I} \\
%& A_\mathcal{J}x=\textbf{0}_{|\mathcal{J}|} \\
%& 0\leq x \leq 1,
%\end{array}\]
%where the binary constraints have now been relaxed to linear constraints. This linear programming relaxation was first proposed in \cite{MalioutovM2012}. As done with compressed sensing, we can consider a noisy setting in which the results of a sanitizer might be incorrect. We consider the linear program, also derived in \cite{MalioutovM2012},
%\begin{equation}
%\label{eq:robust_grouptesting}
%\begin{array}{ll}
%\mbox{minimize} & \sum_i{x_i}+C\sum_i{\epsilon_i}\\
%\mbox{subject to} & A_\mathcal{I}x+\epsilon_\mathcal{I}\geq b_\mathcal{I} \\
%& A_\mathcal{J}x\geq \epsilon_{|\mathcal{J}|} \\
%& 0\leq x \leq 1\\
%&\epsilon\geq0\\
%&\epsilon_\mathcal{I}\leq 1.
%\end{array}\end{equation}
%The objective now trades off two objectives: minimizing the number of tokens needed to explain the sanitizer versus minimizing the penalty for ignoring the results of the sanitizer for any given instance. Mistakes by the sanitizer are penalized with rate $C$ which is a tunable parameter to the model. We solve problems of the form (\ref{eq:robust_grouptesting}) in order to explain sanitizers.
%
