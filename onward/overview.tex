\section{Technical Overview}

We assume a finite alphabet $\Sigma=\{ \tau,\tau',\ldots \}$ of tokens used to express test inputs. An input is a member of $\Sigma^{\star}$. For example, input ${\sf <script>alert('1')</script>}$ consists of tokens ${\sf <script>}$, ${\sf alert('1')}$ and ${\sf </script>}$.

An \emph{element} is a token tuple, e.g. the 1-ary tuple ${\sf (<script>)}$ (or simply ${\sf <script>}$) or the 2-ary tuple ${\sf (<script>,</script>)}$. We say that input $i=\tau_1 \cdot \ldots \cdot \tau_n$ matches element $e$ or arity $k$, denoted $i \models e$, if
$$
\exists 1 \leq i_1 \leq \ldots \leq i_k \leq n.\ \bigwedge_{1 \leq m \leq k}
i(i_m) = e(m)  
$$
That is, the input contains a subsequence of tokens that matches the tokens specified as the element.

Input filtering (by which we refer collectively to both sanitization and validation) is modeled as a regular-expression membership judgment. This is, in fact, the common way of implementing such filters in practice \cite{XXX}. We follow the standard syntax for expressing a regular expression:
$$
	r = \epsilon\ |\ \{ \sigma \}_{\sigma \in \Sigma}\ |\ r + r\ |\ r \cdot r\ |\ r^{\star}
$$
For simplicity, and without loss of generality, we fix the behavior of the filter, such that given filter $r$ and input $i$, $i$ is in the language of $r$ --- denoted $i \in L_r$ --- iff $r$ \emph{rejects} $i$. That is, the filter matches against the input iff the input is considered illegal.

The problem we target in this paper is to characterize the behavior of a filter efficiently under black-box assumptions. Informally, what we mean by ``efficiently'' is that only a small fraction of the test inputs are tried. What we mean by ``black-box assumptions'' is that the testing system has no access to any of the code, and its behavior is based solely on the observed input/output pairs.



